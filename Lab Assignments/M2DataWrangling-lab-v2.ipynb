{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Stack Overflow survey data\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65437 entries, 0 to 65436\n",
      "Columns: 114 entries, ResponseId to JobSat\n",
      "dtypes: float64(13), int64(1), object(100)\n",
      "memory usage: 56.9+ MB\n",
      "None\n",
      "\n",
      "Missing Values per Column:\n",
      "ResponseId                 0\n",
      "MainBranch                 0\n",
      "Age                        0\n",
      "Employment                 0\n",
      "RemoteWork             10631\n",
      "                       ...  \n",
      "JobSatPoints_11        35992\n",
      "SurveyLength            9255\n",
      "SurveyEase              9199\n",
      "ConvertedCompYearly    42002\n",
      "JobSat                 36311\n",
      "Length: 114, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# Summarize the dataset: display column data types, counts, and missing values\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Statistics for Numerical Columns:\n",
      "         ResponseId      CompTotal       WorkExp  JobSatPoints_1  \\\n",
      "count  65437.000000   3.374000e+04  29658.000000    29324.000000   \n",
      "mean   32719.000000  2.963841e+145     11.466957       18.581094   \n",
      "std    18890.179119  5.444117e+147      9.168709       25.966221   \n",
      "min        1.000000   0.000000e+00      0.000000        0.000000   \n",
      "25%    16360.000000   6.000000e+04      4.000000        0.000000   \n",
      "50%    32719.000000   1.100000e+05      9.000000       10.000000   \n",
      "75%    49078.000000   2.500000e+05     16.000000       22.000000   \n",
      "max    65437.000000  1.000000e+150     50.000000      100.000000   \n",
      "\n",
      "       JobSatPoints_4  JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  \\\n",
      "count    29393.000000    29411.000000    29450.000000     29448.00000   \n",
      "mean         7.522140       10.060857       24.343232        22.96522   \n",
      "std         18.422661       21.833836       27.089360        27.01774   \n",
      "min          0.000000        0.000000        0.000000         0.00000   \n",
      "25%          0.000000        0.000000        0.000000         0.00000   \n",
      "50%          0.000000        0.000000       20.000000        15.00000   \n",
      "75%          5.000000       10.000000       30.000000        30.00000   \n",
      "max        100.000000      100.000000      100.000000       100.00000   \n",
      "\n",
      "       JobSatPoints_8  JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  \\\n",
      "count    29456.000000    29456.000000     29450.000000     29445.000000   \n",
      "mean        20.278165       16.169432        10.955713         9.953948   \n",
      "std         26.108110       24.845032        22.906263        21.775652   \n",
      "min          0.000000        0.000000         0.000000         0.000000   \n",
      "25%          0.000000        0.000000         0.000000         0.000000   \n",
      "50%         10.000000        5.000000         0.000000         0.000000   \n",
      "75%         25.000000       20.000000        10.000000        10.000000   \n",
      "max        100.000000      100.000000       100.000000       100.000000   \n",
      "\n",
      "       ConvertedCompYearly        JobSat  \n",
      "count         2.343500e+04  29126.000000  \n",
      "mean          8.615529e+04      6.935041  \n",
      "std           1.867570e+05      2.088259  \n",
      "min           1.000000e+00      0.000000  \n",
      "25%           3.271200e+04      6.000000  \n",
      "50%           6.500000e+04      7.000000  \n",
      "75%           1.079715e+05      8.000000  \n",
      "max           1.625660e+07     10.000000  \n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# Generate basic statistics for numerical columns\n",
    "print(\"Basic Statistics for Numerical Columns:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values in Country Column:\n",
      "['United States of America'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Canada' 'Norway'\n",
      " 'Uzbekistan' 'Serbia' 'Poland' 'Philippines' 'Bulgaria' 'Switzerland'\n",
      " 'India' 'Germany' 'Ireland' 'Italy' 'Ukraine' 'Australia' 'Brazil'\n",
      " 'Japan' 'Austria' 'Iran, Islamic Republic of...' 'France' 'Saudi Arabia'\n",
      " 'Romania' 'Turkey' 'Nepal' 'Algeria' 'Sweden' 'Netherlands' 'Croatia'\n",
      " 'Pakistan' 'Czech Republic' 'Republic of North Macedonia' 'Finland'\n",
      " 'Slovakia' 'Russian Federation' 'Greece' 'Israel' 'Belgium' 'Mexico'\n",
      " 'United Republic of Tanzania' 'Hungary' 'Argentina' 'Portugal'\n",
      " 'Sri Lanka' 'Latvia' 'China' 'Singapore' 'Lebanon' 'Spain' 'South Africa'\n",
      " 'Lithuania' 'Viet Nam' 'Dominican Republic' 'Indonesia' 'Kosovo'\n",
      " 'Morocco' 'Taiwan' 'Georgia' 'San Marino' 'Tunisia' 'Bangladesh'\n",
      " 'Nigeria' 'Liechtenstein' 'Denmark' 'Ecuador' 'Malaysia' 'Albania'\n",
      " 'Azerbaijan' 'Chile' 'Ghana' 'Peru' 'Bolivia' 'Egypt' 'Luxembourg'\n",
      " 'Montenegro' 'Cyprus' 'Paraguay' 'Kazakhstan' 'Slovenia' 'Jordan'\n",
      " 'Venezuela, Bolivarian Republic of...' 'Costa Rica' 'Jamaica' 'Thailand'\n",
      " 'Nicaragua' 'Myanmar' 'Republic of Korea' 'Rwanda'\n",
      " 'Bosnia and Herzegovina' 'Benin' 'El Salvador' 'Zimbabwe' 'Afghanistan'\n",
      " 'Estonia' 'Malta' 'Uruguay' 'Belarus' 'Colombia' 'Republic of Moldova'\n",
      " 'Isle of Man' 'Nomadic' 'New Zealand' 'Palestine' 'Armenia'\n",
      " 'United Arab Emirates' 'Maldives' 'Ethiopia' 'Fiji' 'Guatemala' 'Uganda'\n",
      " 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon' 'Bahamas' 'South Korea'\n",
      " 'Iceland' 'Honduras' 'Hong Kong (S.A.R.)'\n",
      " \"Lao People's Democratic Republic\" 'Mongolia' 'Cambodia' 'Madagascar'\n",
      " 'Angola' 'Democratic Republic of the Congo' 'Syrian Arab Republic' 'Iraq'\n",
      " 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia' 'Swaziland' \"Côte d'Ivoire\"\n",
      " 'Kuwait' 'Tajikistan' 'Burundi' 'Trinidad and Tobago' 'Mauritania'\n",
      " 'Sierra Leone' 'Panama' 'Somalia' 'North Korea' 'Dominica' 'Guyana'\n",
      " 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " \"Democratic People's Republic of Korea\" 'Qatar' 'Sudan' 'Cameroon'\n",
      " 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi' 'Burkina Faso'\n",
      " 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau' 'Mozambique'\n",
      " 'Central African Republic' 'Equatorial Guinea' 'Suriname' 'Belize'\n",
      " 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam' 'Bhutan'\n",
      " 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia, Federated States of...'\n",
      " 'Haiti' nan 'Nauru' 'Liberia' 'Chad' 'Djibouti' 'Solomon Islands']\n",
      "\n",
      "Missing Values in Country Column: 6507\n",
      "Empty or Whitespace Entries in Country Column: 0\n",
      "Common Inconsistent Entries (e.g., 'N/A', 'Other'):\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# Identify inconsistent or irrelevant entries in the Country column\n",
    "print(\"Unique Values in Country Column:\")\n",
    "unique_countries = df['Country'].unique()\n",
    "print(unique_countries)\n",
    "\n",
    "# Check for missing, empty, or suspicious entries\n",
    "print(\"\\nMissing Values in Country Column:\", df['Country'].isna().sum())\n",
    "print(\"Empty or Whitespace Entries in Country Column:\", \n",
    "      len(df[df['Country'].str.strip() == ''] if df['Country'].dtype == \"object\" else 0))\n",
    "print(\"Common Inconsistent Entries (e.g., 'N/A', 'Other'):\")\n",
    "inconsistent_entries = df[df['Country'].isin(['N/A', 'Other', 'Unknown', 'NA'])][['Country']]\n",
    "print(inconsistent_entries.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Unique Values in Country Column:\n",
      "['United States' 'United Kingdom' 'Canada' 'Norway' 'Uzbekistan' 'Serbia'\n",
      " 'Poland' 'Philippines' 'Bulgaria' 'Switzerland' 'India' 'Germany'\n",
      " 'Ireland' 'Italy' 'Ukraine' 'Australia' 'Brazil' 'Japan' 'Austria'\n",
      " 'Iran, Islamic Republic of...' 'France' 'Saudi Arabia' 'Romania' 'Turkey'\n",
      " 'Nepal' 'Algeria' 'Sweden' 'Netherlands' 'Croatia' 'Pakistan'\n",
      " 'Czech Republic' 'Republic of North Macedonia' 'Finland' 'Slovakia'\n",
      " 'Russian Federation' 'Greece' 'Israel' 'Belgium' 'Mexico'\n",
      " 'United Republic of Tanzania' 'Hungary' 'Argentina' 'Portugal'\n",
      " 'Sri Lanka' 'Latvia' 'China' 'Singapore' 'Lebanon' 'Spain' 'South Africa'\n",
      " 'Lithuania' 'Viet Nam' 'Dominican Republic' 'Indonesia' 'Kosovo'\n",
      " 'Morocco' 'Taiwan' 'Georgia' 'San Marino' 'Tunisia' 'Bangladesh'\n",
      " 'Nigeria' 'Liechtenstein' 'Denmark' 'Ecuador' 'Malaysia' 'Albania'\n",
      " 'Azerbaijan' 'Chile' 'Ghana' 'Peru' 'Bolivia' 'Egypt' 'Luxembourg'\n",
      " 'Montenegro' 'Cyprus' 'Paraguay' 'Kazakhstan' 'Slovenia' 'Jordan'\n",
      " 'Venezuela, Bolivarian Republic of...' 'Costa Rica' 'Jamaica' 'Thailand'\n",
      " 'Nicaragua' 'Myanmar' 'Republic of Korea' 'Rwanda'\n",
      " 'Bosnia and Herzegovina' 'Benin' 'El Salvador' 'Zimbabwe' 'Afghanistan'\n",
      " 'Estonia' 'Malta' 'Uruguay' 'Belarus' 'Colombia' 'Republic of Moldova'\n",
      " 'Isle of Man' 'Nomadic' 'New Zealand' 'Palestine' 'Armenia'\n",
      " 'United Arab Emirates' 'Maldives' 'Ethiopia' 'Fiji' 'Guatemala' 'Uganda'\n",
      " 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon' 'Bahamas' 'South Korea'\n",
      " 'Iceland' 'Honduras' 'Hong Kong (S.A.R.)'\n",
      " \"Lao People's Democratic Republic\" 'Mongolia' 'Cambodia' 'Madagascar'\n",
      " 'Angola' 'Democratic Republic of the Congo' 'Syrian Arab Republic' 'Iraq'\n",
      " 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia' 'Swaziland' \"Côte d'Ivoire\"\n",
      " 'Kuwait' 'Tajikistan' 'Burundi' 'Trinidad and Tobago' 'Mauritania'\n",
      " 'Sierra Leone' 'Panama' 'Somalia' 'North Korea' 'Dominica' 'Guyana'\n",
      " 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " \"Democratic People's Republic of Korea\" 'Qatar' 'Sudan' 'Cameroon'\n",
      " 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi' 'Burkina Faso'\n",
      " 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau' 'Mozambique'\n",
      " 'Central African Republic' 'Equatorial Guinea' 'Suriname' 'Belize'\n",
      " 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam' 'Bhutan'\n",
      " 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia, Federated States of...'\n",
      " 'Haiti' nan 'Nauru' 'Liberia' 'Chad' 'Djibouti' 'Solomon Islands']\n",
      "\n",
      "Standardized Unique Values in EdLevel Column:\n",
      "['High school or less' 'Bachelor’s degree (B.A., B.S., B.Eng., etc.)'\n",
      " 'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)' 'Some college'\n",
      " 'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)'\n",
      " 'Professional degree (JD, MD, Ph.D, Ed.D, etc.)' 'Associate degree'\n",
      " 'Something else' nan]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Standardize entries in the Country column\n",
    "country_mapping = {\n",
    "    'United States': 'United States',\n",
    "    'USA': 'United States',\n",
    "    'U.S.': 'United States',\n",
    "    'United States of America': 'United States',\n",
    "    'UK': 'United Kingdom',\n",
    "    'United Kingdom of Great Britain and Northern Ireland': 'United Kingdom',\n",
    "    'Great Britain': 'United Kingdom',\n",
    "    'N/A': None,  # Treat 'N/A' as missing\n",
    "    'Other': None,  # Treat 'Other' as missing\n",
    "    'Unknown': None  # Treat 'Unknown' as missing\n",
    "}\n",
    "\n",
    "df['Country'] = df['Country'].replace(country_mapping)\n",
    "\n",
    "# Standardize entries in the EdLevel column\n",
    "edlevel_mapping = {\n",
    "    'Bachelor’s degree (BA, BS, B.Eng., etc.)': 'Bachelor’s degree',\n",
    "    'Bachelor': 'Bachelor’s degree',\n",
    "    'BSc': 'Bachelor’s degree',\n",
    "    'Master’s degree (MA, MS, M.Eng., MBA, etc.)': 'Master’s degree',\n",
    "    'Master': 'Master’s degree',\n",
    "    'MSc': 'Master’s degree',\n",
    "    'Doctoral degree (Ph.D., Ed.D., etc.)': 'Doctoral degree',\n",
    "    'PhD': 'Doctoral degree',\n",
    "    'Associate degree (A.A., A.S., etc.)': 'Associate degree',\n",
    "    'Some college/university study without earning a degree': 'Some college',\n",
    "    'No formal education past high school': 'High school or less',\n",
    "    'Primary/elementary school': 'High school or less',\n",
    "    'Secondary school (e.g., American high school, German Realschule, etc.)': 'High school or less',\n",
    "    'N/A': None,  # Treat 'N/A' as missing\n",
    "    'Other': None  # Treat 'Other' as missing\n",
    "}\n",
    "\n",
    "df['EdLevel'] = df['EdLevel'].replace(edlevel_mapping)\n",
    "\n",
    "# Verify the standardization\n",
    "print(\"Standardized Unique Values in Country Column:\")\n",
    "print(df['Country'].unique())\n",
    "print(\"\\nStandardized Unique Values in EdLevel Column:\")\n",
    "print(df['EdLevel'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with One-Hot Encoded Employment Columns:\n",
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                                High school or less   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3                                       Some college   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ...  \\\n",
      "0                                                NaN  ...   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...   \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Not employed, and not looking for work;Student, part-time  \\\n",
      "0                                              False                                                                           \n",
      "1                                              False                                                                           \n",
      "2                                              False                                                                           \n",
      "3                                              False                                                                           \n",
      "4                                              False                                                                           \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Retired  \\\n",
      "0                                              False                         \n",
      "1                                              False                         \n",
      "2                                              False                         \n",
      "3                                              False                         \n",
      "4                                              False                         \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Student, part-time  \\\n",
      "0                                              False                                    \n",
      "1                                              False                                    \n",
      "2                                              False                                    \n",
      "3                                              False                                    \n",
      "4                                              False                                    \n",
      "\n",
      "  Employment_Student, full-time;Retired  \\\n",
      "0                                 False   \n",
      "1                                 False   \n",
      "2                                 False   \n",
      "3                                 False   \n",
      "4                                 False   \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time  \\\n",
      "0                                            False   \n",
      "1                                            False   \n",
      "2                                            False   \n",
      "3                                            False   \n",
      "4                                            False   \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time;Employed, part-time  \\\n",
      "0                                              False                     \n",
      "1                                              False                     \n",
      "2                                              False                     \n",
      "3                                              False                     \n",
      "4                                              False                     \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time;Retired  \\\n",
      "0                                              False         \n",
      "1                                              False         \n",
      "2                                              False         \n",
      "3                                              False         \n",
      "4                                              False         \n",
      "\n",
      "  Employment_Student, part-time  \\\n",
      "0                         False   \n",
      "1                         False   \n",
      "2                         False   \n",
      "3                         False   \n",
      "4                         False   \n",
      "\n",
      "  Employment_Student, part-time;Employed, part-time  \\\n",
      "0                                             False   \n",
      "1                                             False   \n",
      "2                                             False   \n",
      "3                                             False   \n",
      "4                                             False   \n",
      "\n",
      "  Employment_Student, part-time;Retired  \n",
      "0                                 False  \n",
      "1                                 False  \n",
      "2                                 False  \n",
      "3                                 False  \n",
      "4                                 False  \n",
      "\n",
      "[5 rows x 224 columns]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Encode the Employment column using one-hot encoding\n",
    "employment_encoded = pd.get_dummies(df['Employment'], prefix='Employment')\n",
    "\n",
    "# Concatenate the encoded columns to the original DataFrame\n",
    "df = pd.concat([df, employment_encoded], axis=1)\n",
    "\n",
    "# Display the first few rows to verify the encoding\n",
    "print(\"DataFrame with One-Hot Encoded Employment Columns:\")\n",
    "print(df.head())\n",
    "\n",
    "# Optionally, drop the original Employment column if no longer needed\n",
    "# df = df.drop('Employment', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with the Highest Number of Missing Values:\n",
      "AINextMuch less integrated                                              64289\n",
      "AINextLess integrated                                                   63082\n",
      "AINextNo change                                                         52939\n",
      "AINextMuch more integrated                                              51999\n",
      "EmbeddedAdmired                                                         48704\n",
      "                                                                        ...  \n",
      "Employment_Student, full-time;Student, part-time;Employed, part-time        0\n",
      "Employment_Student, full-time;Student, part-time;Retired                    0\n",
      "Employment_Student, part-time                                               0\n",
      "Employment_Student, part-time;Employed, part-time                           0\n",
      "Employment_Student, part-time;Retired                                       0\n",
      "Length: 224, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Identify columns with the highest number of missing values\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "# Sort columns by number of missing values in descending order\n",
    "missing_values_sorted = missing_values.sort_values(ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Columns with the Highest Number of Missing Values:\")\n",
    "print(missing_values_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in ConvertedCompYearly After Imputation: 0\n",
      "Basic Statistics for ConvertedCompYearly After Imputation:\n",
      "count    6.543700e+04\n",
      "mean     7.257636e+04\n",
      "std      1.122207e+05\n",
      "min      1.000000e+00\n",
      "25%      6.500000e+04\n",
      "50%      6.500000e+04\n",
      "75%      6.500000e+04\n",
      "max      1.625660e+07\n",
      "Name: ConvertedCompYearly, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Impute missing values in the ConvertedCompYearly column with the median\n",
    "median_comp = df['ConvertedCompYearly'].median()\n",
    "df['ConvertedCompYearly'] = df['ConvertedCompYearly'].fillna(median_comp)\n",
    "\n",
    "# Verify the imputation\n",
    "print(\"Missing Values in ConvertedCompYearly After Imputation:\", df['ConvertedCompYearly'].isna().sum())\n",
    "print(\"Basic Statistics for ConvertedCompYearly After Imputation:\")\n",
    "print(df['ConvertedCompYearly'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in RemoteWork After Imputation: 0\n",
      "Value Counts for RemoteWork After Imputation:\n",
      "RemoteWork\n",
      "Hybrid (some remote, some in-person)    33646\n",
      "Remote                                  20831\n",
      "In-person                               10960\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Impute missing values in the RemoteWork column with the most frequent value (mode)\n",
    "mode_remote = df['RemoteWork'].mode()[0]  # Get the most frequent value\n",
    "df['RemoteWork'] = df['RemoteWork'].fillna(mode_remote)\n",
    "\n",
    "# Verify the imputation\n",
    "print(\"Missing Values in RemoteWork After Imputation:\", df['RemoteWork'].isna().sum())\n",
    "print(\"Value Counts for RemoteWork After Imputation:\")\n",
    "print(df['RemoteWork'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "min_val = df['ConvertedCompYearly'].min()\n",
    "max_val = df['ConvertedCompYearly'].max()\n",
    "df['ConvertedCompYearly_Scaled'] = (df['ConvertedCompYearly'] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Statistics for Log-Transformed ConvertedCompYearly:\n",
      "count    65437.000000\n",
      "mean        10.976053\n",
      "std          0.851456\n",
      "min          0.693147\n",
      "25%         11.082158\n",
      "50%         11.082158\n",
      "75%         11.082158\n",
      "max         16.604010\n",
      "Name: ConvertedCompYearly_Log, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Import the required library\n",
    "import numpy as np\n",
    "\n",
    "# Log-transform the ConvertedCompYearly column\n",
    "# Add a small constant (e.g., 1) to handle any zero values\n",
    "df['ConvertedCompYearly_Log'] = np.log(df['ConvertedCompYearly'] + 1)\n",
    "\n",
    "# Verify the transformation\n",
    "print(\"Basic Statistics for Log-Transformed ConvertedCompYearly:\")\n",
    "print(df['ConvertedCompYearly_Log'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts for ExperienceLevel:\n",
      "ExperienceLevel\n",
      "Expert       18460\n",
      "Senior       12653\n",
      "Mid-level    10834\n",
      "Junior        9663\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First Few Rows with ExperienceLevel:\n",
      "   YearsCodePro ExperienceLevel\n",
      "0           NaN             NaN\n",
      "1          17.0          Expert\n",
      "2          27.0          Expert\n",
      "3           NaN             NaN\n",
      "4           NaN             NaN\n"
     ]
    }
   ],
   "source": [
    "# Import the required library\n",
    "import pandas as pd\n",
    "\n",
    "# Clean and convert YearsCodePro to numeric\n",
    "# Define mapping for non-numeric values\n",
    "years_mapping = {\n",
    "    'Less than 1 year': 0.5,  # Treat as 0.5 years\n",
    "    'More than 50 years': 50  # Treat as 50 years\n",
    "}\n",
    "\n",
    "# Replace non-numeric values\n",
    "df['YearsCodePro'] = df['YearsCodePro'].replace(years_mapping)\n",
    "\n",
    "# Convert the column to numeric, coercing errors to NaN\n",
    "df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "\n",
    "# Define bins and labels for experience levels\n",
    "bins = [-float('inf'), 2, 5, 10, float('inf')]  # Bins for 0-2, 3-5, 6-10, >10 years\n",
    "labels = ['Junior', 'Mid-level', 'Senior', 'Expert']\n",
    "\n",
    "# Create the ExperienceLevel column\n",
    "df['ExperienceLevel'] = pd.cut(df['YearsCodePro'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Verify the new column\n",
    "print(\"Value Counts for ExperienceLevel:\")\n",
    "print(df['ExperienceLevel'].value_counts())\n",
    "print(\"\\nFirst Few Rows with ExperienceLevel:\")\n",
    "print(df[['YearsCodePro', 'ExperienceLevel']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
